{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjuAVgrxmIo3"
   },
   "source": [
    "# **Working with RDD (Resilient Distributed Dataset)**\n",
    "\n",
    "**`Udemy Course: Best Hands-on Big Data Practices and Use Cases using PySpark`**\n",
    "\n",
    "**`Author: Amin Karami (PhD, FHEA)`**\n",
    "\n",
    "---\n",
    "\n",
    "**Resilient Distributed Dataset (RDD)**: RDD is the fundamental data structure of Spark. It is fault-tolerant (resilient) and immutable distributed collections of any type of objects.\n",
    "\n",
    "source: https://spark.apache.org/docs/latest/rdd-programming-guide.html\n",
    "\n",
    "source: https://spark.apache.org/docs/latest/api/python/reference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0LWTJaC8mHL5"
   },
   "outputs": [],
   "source": [
    "########## ONLY in Colab ##########\n",
    "!pip3 install pyspark\n",
    "########## ONLY in Colab ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-riUQ6WTHDl"
   },
   "outputs": [],
   "source": [
    "########## ONLY in Ubuntu Machine ##########\n",
    "# Load Spark engine\n",
    "!pip3 install -q findspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "########## ONLY in Ubuntu Machine ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3pTfRiwTMeY"
   },
   "outputs": [],
   "source": [
    "# Linking with Spark\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_ALGTfeTPN-"
   },
   "outputs": [],
   "source": [
    "# Initializing Spark\n",
    "conf = SparkConf().setAppName(\"RDD_practice\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quQ_GBpgWLRK"
   },
   "source": [
    "# **Part 1: Create RDDs and Basic Operations**\n",
    "# **There are two ways to create RDDs:**\n",
    "\n",
    "1.   Parallelizing an existing collection in your driver program\n",
    "2.   Referencing a dataset in an external storage system, such as a shared filesystem, HDFS, HBase, or any data source offering a Hadoop InputFormat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILkhrdMMTu9m"
   },
   "outputs": [],
   "source": [
    "# Generate random data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1n39Bv24XHjt"
   },
   "outputs": [],
   "source": [
    "# Create RDD:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8aOYoMLX7Er"
   },
   "outputs": [],
   "source": [
    "# Data distribution in partitions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EffFOyTYC18"
   },
   "outputs": [],
   "source": [
    "# Print last partition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9TL1kG-Ceo6E"
   },
   "outputs": [],
   "source": [
    "# count():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZmfAahXeryY"
   },
   "outputs": [],
   "source": [
    "# first():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnuGXcKLb8qa"
   },
   "outputs": [],
   "source": [
    "# top():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3xOj1w6teN_a"
   },
   "outputs": [],
   "source": [
    "# distinct():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qE0CJuhlZz1M"
   },
   "outputs": [],
   "source": [
    "# map():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r804677wamjY"
   },
   "outputs": [],
   "source": [
    "# filter(): \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f--VFpvaqRj"
   },
   "outputs": [],
   "source": [
    "# flatMap():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LSPGU35gk-q"
   },
   "outputs": [],
   "source": [
    "# Descriptive statistics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEKBDcW1bvZe"
   },
   "outputs": [],
   "source": [
    "# mapPartitions():\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGi2zdncaoHo"
   },
   "source": [
    "# **Part 2: Advanced RDD Transformations and Actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIKu4KMrdt1k"
   },
   "outputs": [],
   "source": [
    "# union():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmQ3bNUkeMVk"
   },
   "outputs": [],
   "source": [
    "# intersection():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E2g0ep9M8GX8"
   },
   "outputs": [],
   "source": [
    "# Find empty partitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-AopsaZqehmA"
   },
   "outputs": [],
   "source": [
    "# coalesce(numPartitions):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFjDbelJeuoq"
   },
   "outputs": [],
   "source": [
    "# takeSample(withReplacement, num, [seed])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_K41G_W9ezhS"
   },
   "outputs": [],
   "source": [
    "# takeOrdered(n, [ordering])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgBhaTdAeldY"
   },
   "outputs": [],
   "source": [
    "# reduce():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aj8-Q40_eXT2"
   },
   "outputs": [],
   "source": [
    "# reduceByKey():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ii8M3qNMeaHC"
   },
   "outputs": [],
   "source": [
    "# sortByKey():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-WYDKd2e0qf"
   },
   "outputs": [],
   "source": [
    "# countByKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bihcXC8DeUEv"
   },
   "outputs": [],
   "source": [
    "# groupByKey():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NzYUXEJhDM9"
   },
   "outputs": [],
   "source": [
    "# lookup(key):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9ThlLGO6z7u"
   },
   "outputs": [],
   "source": [
    "# cache:\n",
    "# By default, each transformed RDD may be recomputed each time you run an action on it.\n",
    "# However, you may also persist an RDD in memory using the persist (or cache) method,\n",
    "# in which case Spark will keep the elements around on the cluster for much faster access the next time you query it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zYpm9hpiqPc"
   },
   "outputs": [],
   "source": [
    "# Persistence (https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-persistence)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Working_with_RDD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
